---
title: "CSLS Lake Metrics - Sensitivity Checks"
output: 
  rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Sensitivity Checks}
  %\VignetteEngine{knitr::rmarkdown}
  \usepackage[utf8]{inputenc}
---

```{r setup, eval=FALSE, echo=FALSE, warning=FALSE, message=FALSE}
library(CSLSlevels)
library(dplyr)
library(reshape2)
library(ggplot2)
library(RColorBrewer)
library(extrafont)
library(lubridate)
library(NISTunits)

csls_levels            <- CSLSlevels::csls_levels
monte_carlo            <- CSLSlevels::monte_carlo
moving_windows         <- CSLSlevels::moving_windows
monte_carlo_metrics    <- CSLSlevels::monte_carlo_metrics
moving_windows_metrics <- CSLSlevels::moving_windows_metrics

text_size <- 12

calculate_fit <- function(summary){
  fit <- summary %>%
         group_by(.data$lake, .data$metric, .data$variable, .data$nyear) %>%
         summarise(PBIAS = 100*abs(mean((.data$sim - .data$obs)/.data$obs, 
                                        na.rm = TRUE)),
                   CV = 100*abs(sd(.data$sim, na.rm = TRUE)/
                        mean(.data$sim, na.rm = TRUE)),
                   RMSE = mean(sqrt((.data$obs - .data$sim)^2),
                               na.rm = TRUE)) %>%
         ungroup() %>%
         as.data.frame()
  fit <- melt(fit, id.vars = c("lake", "metric", "variable", "nyear"))
  colnames(fit) <- c("lake", "metric", "variable", "nyear", "fit", "value")
  return(fit)
}
```

## What's going on with weird increases in error at medium-length timeseries?

It is counterintuitive that accuracy sometimes worsens with medium-length
timeseries. Shouldn't using more of the timeseries always get you closer to the
"true" value of the entire timeseries?

<br>

Let's take a deep dive into one example of this: Long Lake Median Lake Levels.
While bias is consistently low (PBIAS), precision (CV) and accuracy (RMSE)
worsen between lengths of ~45 years to ~60 years before beginning to improve
again.

```{r long_sensitivity, eval=FALSE, echo=FALSE, warning=FALSE, message=FALSE, fig.align='center', fig.width=6.5, fig.height=6}
monte_carlo_fit <- calculate_fit(monte_carlo_metrics)
monte_carlo_fit <- monte_carlo_fit %>%
                   mutate(value = ifelse(.data$metric %in% 
                                           c("median_level",
                                             "exceedance_level",
                                             "exceedance_range",
                                             "median_rise_rate",
                                             "median_fall_rate") &
                                           .data$fit == "RMSE",
                                         NISTmeterTOft(.data$value),
                                         .data$value))
metric_name     <- "median_level"
metric_title    <- ""
variable_title  <- "Month"
variable_breaks <- "sort"
variable_labels <- c("Annual","Jan", "Feb", "Mar", "Apr", "May", "Jun", "Jul",
                    "Aug", "Sep", "Oct", "Nov", "Dec")
variable_colors <- c("#000000", brewer.pal(12, "Paired"))
plot_sensitivity(monte_carlo_fit, metric_name, metric_title, variable_title, 
                 variable_breaks, variable_labels, variable_colors, text_size,
                 vline = NULL)
```

<br>

Ok, weird. Let's take a look at how the median lake level varies as you move the
start date of the moving window for a few representative timeseries lengths: 45
years, 50 years, 55 years, and 60 years. The dashed line represents the "true"
long-term median lake level.

```{r moving_windows, eval=FALSE, echo=FALSE, warning=FALSE, message=FALSE, fig.align='center', fig.width=6.5, fig.height=5}
metric   <- "median_level"
variable <- "0"
lake     <- "Long"

plot_df <- moving_windows_metrics %>%
           filter(.data$lake == !!lake,
                  .data$metric == !!metric,
                  .data$variable == !!variable,
                  .data$nyear %in% c(45, 50, 55, 60))
plot_medians <- plot_df %>%
                group_by(.data$nyear) %>%
                summarise(level = median(.data$sim)) %>%
                ungroup() %>%
                as.data.frame()

ggplot() +
  geom_line(data = plot_df,
            aes(x = 1904 + nsim, y = sim),
            color = "grey70") +
  geom_line(data = plot_df,
             aes(x = 1904 + nsim, y = obs),
             color = "black",
             linetype = "dashed") +
  facet_grid(~nyear) +
  labs(x = "Start Year", 
       y = "Median Level (m)") +
  theme_bw() +
  theme(text = element_text(family = "Segoe UI Semilight",
                                        size = 12),
        axis.text.x = element_text(angle = 90))
```

<br>

Now we see a bit of a pattern. The first half of the timeseries generally has
lower values than the second half of the timeseries. Overall, these values are
pretty balanced around the "true" median (i.e., PBIAS is close to zero). But as
you increase from a 45 year timeseries to a 60 year timeseries, the mean
distance from the "true" median increases (i.e., RMSE increases) and the range
of values increaes (i.e., CV increases).

<br>

Ok, now let's pick two representative starting years and look more closely at
why a 60-year timeseries from 1920-1979 is so far below the "true" median and
why a 60-year timeseries from 1939-1998 is so far above the "true" median.

```{r moving_windows02, eval=FALSE, echo=FALSE, warning=FALSE, message=FALSE, fig.align='center', fig.width=6.5, fig.height=5}

long_1920 <- csls_levels %>%
             filter(.data$lake == "Long",
                    year(.data$date) >= 1920,
                    year(.data$date) <= 1979)
long_1920$row_no <- as.numeric(rownames(long_1920))
long_1939 <- csls_levels %>%
             filter(.data$lake == "Long",
                    year(.data$date) >= 1939,
                    year(.data$date) <= 1998)
long_1939$row_no <- as.numeric(rownames(long_1939))

ggplot() +
  geom_line(data = long_1920,
            aes(x = row_no/12, y = level_pred, color = "1920 start")) +
  geom_line(data = long_1939,
             aes(x = row_no/12, y = level_pred, color = "1939 start")) +
  labs(x = "Years", 
       y = "Lake Level (m)") +
  scale_color_manual(name = "",
                     breaks = c("1920 start","1939 start"),
                     values = c("grey70", "black")) +
  theme_bw() +
  theme(text = element_text(family = "Segoe UI Semilight",
                                        size = 12),
        legend.position = "top")
```
<br>

By plotting them on top of one another, it's clear that a 60-year timeseries
just happens to correspond with ~1.5 cycles of long-term lake level rise & fall.
If you start in 1920, you capture low-high-low periods - your median level is
biased low. If you start in 1938, you capture high-low-high periods - your median
level is biased high.

So this weird blip in error metrics is actually important for us to pay
attention to. It's truly telling us that 60-year timeseries are a bad choice for
representing the long-term dynamics of Long Lake.
